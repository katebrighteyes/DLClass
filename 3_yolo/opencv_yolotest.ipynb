{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"opencv_yolotest.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQWuIkB1Kroe","executionInfo":{"status":"ok","timestamp":1637762707695,"user_tz":-540,"elapsed":26242,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}},"outputId":"d06d6e87-0d11-4e3e-cffe-d9b21d9f3496"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GzEIbHvjLSm0","executionInfo":{"status":"ok","timestamp":1637762713033,"user_tz":-540,"elapsed":878,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}},"outputId":"57457a43-4237-44d1-ba2b-46c63adb4e33"},"source":["cd gdrive/MyDrive/DlClass"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/DlClass\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qoX7bsLTLYsh","executionInfo":{"status":"ok","timestamp":1637762716083,"user_tz":-540,"elapsed":2099,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}},"outputId":"272a5dd1-0147-41ed-e2ba-a1c992279521"},"source":["ls"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34m1_classification\u001b[0m/  \u001b[01;34m3_yolo\u001b[0m/                ObjectDetection-YOLO.zip  run3.mp4\n","\u001b[01;34m2_ssd\u001b[0m/             \u001b[01;34mObjectDetection-YOLO\u001b[0m/  \u001b[01;34mpytorch-ssd\u001b[0m/\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7K3IOITnLbXx","executionInfo":{"status":"ok","timestamp":1637762722333,"user_tz":-540,"elapsed":244,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}},"outputId":"ae80f2f2-1427-41eb-98b1-30d2fc6cdb09"},"source":["cd ObjectDetection-YOLO/"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/DlClass/ObjectDetection-YOLO\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pC0Fh-coLj-r","executionInfo":{"status":"ok","timestamp":1637766348209,"user_tz":-540,"elapsed":1151,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}},"outputId":"44204524-6e41-4404-944d-713e06daa0f3"},"source":["!python3 object_detection_yolo.py --image=bird.jpg --device 'cpu'"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CPU device.\n",": cannot connect to X server \n"]}]},{"cell_type":"code","metadata":{"id":"G0wGdoBG5U2-","executionInfo":{"status":"ok","timestamp":1637762734534,"user_tz":-540,"elapsed":242,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}}},"source":["import cv2"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"blXVyBgM5fCG","executionInfo":{"status":"ok","timestamp":1637762736641,"user_tz":-540,"elapsed":6,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}},"outputId":"bae11853-0f01-46a7-bbfb-34bceb361cca"},"source":["cv2.__version__"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'4.1.2'"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"mMV0DjA_W35A","executionInfo":{"status":"ok","timestamp":1637766362571,"user_tz":-540,"elapsed":282,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}}},"source":["import cv2 as cv\n","import argparse\n","import sys\n","import numpy as np\n","import os.path\n","\n","# Initialize the parameters\n","confThreshold = 0.5  #Confidence threshold\n","nmsThreshold = 0.4   #Non-maximum suppression threshold\n","inpWidth = 416       #Width of network's input image\n","inpHeight = 416      #Height of network's input image\n"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"rB_LnjnmW5WH","executionInfo":{"status":"ok","timestamp":1637762824124,"user_tz":-540,"elapsed":235,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}}},"source":["classesFile = \"coco.names\"\n","classes = None\n","with open(classesFile, 'rt') as f:\n","    classes = f.read().rstrip('\\n').split('\\n')\n","\n","# Give the configuration and weight files for the model and load the network using them.\n","    modelConfiguration = \"yolov3.cfg\"\n","    modelWeights = \"yolov3.weights\"\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41DKNvlgXAHd","executionInfo":{"status":"ok","timestamp":1637762842725,"user_tz":-540,"elapsed":1956,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}},"outputId":"a700365d-5e32-47f3-bdbd-fe52f653dc2f"},"source":["net = cv.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n","net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n","net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n","print('Using CPU device.')\n"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CPU device.\n"]}]},{"cell_type":"code","metadata":{"id":"oJZilrWeYRRw","executionInfo":{"status":"ok","timestamp":1637766373450,"user_tz":-540,"elapsed":265,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}}},"source":["# Get the names of the output layers\n","def getOutputsNames(net):\n","    # Get the names of all the layers in the network\n","    layersNames = net.getLayerNames()\n","    # Get the names of the output layers, i.e. the layers with unconnected outputs\n","    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n","\n","# Draw the predicted bounding box\n","def drawPred(frame, classId, conf, left, top, right, bottom):\n","    # Draw a bounding box.\n","    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n","    \n","    label = '%.2f' % conf\n","        \n","    # Get the label for the class name and its confidence\n","    if classes:\n","        assert(classId < len(classes))\n","        label = '%s:%s' % (classes[classId], label)\n","\n","    #Display the label at the top of the bounding box\n","    labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n","    top = max(top, labelSize[1])\n","    cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv.FILLED)\n","    cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)\n"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-V9S9mpe-q2","executionInfo":{"status":"ok","timestamp":1637766418677,"user_tz":-540,"elapsed":235,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}}},"source":["# Remove the bounding boxes with low confidence using non-maxima suppression\n","def postprocess(frame, outs):\n","    frameHeight = frame.shape[0]\n","    frameWidth = frame.shape[1]\n","\n","    # Scan through all the bounding boxes output from the network and keep only the\n","    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n","    classIds = []\n","    confidences = []\n","    boxes = []\n","    for out in outs:\n","        for detection in out:\n","            scores = detection[5:]\n","            classId = np.argmax(scores)\n","            confidence = scores[classId]\n","            if confidence > confThreshold:\n","                center_x = int(detection[0] * frameWidth)\n","                center_y = int(detection[1] * frameHeight)\n","                width = int(detection[2] * frameWidth)\n","                height = int(detection[3] * frameHeight)\n","                left = int(center_x - width / 2)\n","                top = int(center_y - height / 2)\n","                classIds.append(classId)\n","                confidences.append(float(confidence))\n","                boxes.append([left, top, width, height])\n","\n","    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n","    # lower confidences.\n","    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n","    for i in indices:\n","        i = i[0]\n","        box = boxes[i]\n","        left = box[0]\n","        top = box[1]\n","        width = box[2]\n","        height = box[3]\n","        drawPred(frame, classIds[i], confidences[i], left, top, left + width, top + height)\n"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"1X3grkW-XLZf","executionInfo":{"status":"ok","timestamp":1637762929588,"user_tz":-540,"elapsed":241,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}}},"source":["def image_infer(imagename):\n","    if not os.path.isfile(imagename):\n","        print(\"Input image file \", args.image, \" doesn't exist\")\n","        sys.exit(1)\n","    cap = cv.VideoCapture(args.image)\n","    outputFile = args.image[:-4]+'_yolo_out_py.jpg'\n","\n","    hasFrame, frame = cap.read()\n","    if not hasFrame:\n","      print(\"no frame !!!\")\n","      cap.release()\n","\n","    # Create a 4D blob from a frame.\n","    blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n","\n","    # Sets the input to the network\n","    net.setInput(blob)\n","\n","    # Runs the forward pass to get output of the output layers\n","    outs = net.forward(getOutputsNames(net))\n","\n","    # Remove the bounding boxes with low confidence\n","    postprocess(frame, outs)\n","\n","    # Put efficiency information. The function getPerfProfile returns the overall time for inference(t) and the timings for each of the layers(in layersTimes)\n","    t, _ = net.getPerfProfile()\n","    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\n","    cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n","\n","    # Write the frame with the detection boxes\n","    cv.imwrite(outputFile, frame.astype(np.uint8))    \n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"y_WjVla_-_ju","executionInfo":{"status":"ok","timestamp":1637766430979,"user_tz":-540,"elapsed":223,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}}},"source":["def imagefile_infer(imagename):\n","    if not os.path.isfile(imagename):\n","        print(\"Input image file \", imagename, \" doesn't exist\")\n","        sys.exit(1)\n","    print(\"Input image file \", imagename)\n","    cap = cv.VideoCapture(imagename)\n","\n","    outputFile = imagename[:-4]+'_yolo_out.jpg'\n","    print(outputFile)\n","\n","    frame = None\n","    hasFrame, frame = cap.read()\n","    if not hasFrame:\n","        print(\"no frame !!!\")\n","\n","    else :\n","        print(\"has frame !!!\")\n","        # Create a 4D blob from a frame.\n","        blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n","\n","        # Sets the input to the network\n","        net.setInput(blob)\n","\n","        # Runs the forward pass to get output of the output layers\n","        outs = net.forward(getOutputsNames(net))\n","\n","        # Remove the bounding boxes with low confidence\n","        postprocess(frame, outs)\n","\n","        # Put efficiency information. The function getPerfProfile returns the overall time for inference(t) and the timings for each of the layers(in layersTimes)\n","        t, _ = net.getPerfProfile()\n","        label = 'Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\n","        cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n","\n","        # Write the frame with the detection boxes\n","        cv.imwrite(outputFile, frame.astype(np.uint8))    \n","\n","    cap.release()"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"WhgYpjbmfSZY","executionInfo":{"status":"ok","timestamp":1637766434334,"user_tz":-540,"elapsed":286,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}}},"source":["def imShow(path):\n","  import cv2\n","  import matplotlib.pyplot as plt\n","  %matplotlib inline\n","\n","  image = cv2.imread(path)\n","  height, width = image.shape[:2]\n","  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n","\n","  fig = plt.gcf()\n","  fig.set_size_inches(9, 5)\n","  plt.axis(\"off\")\n","  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n","  plt.show()"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkmoVY8kS3Xg","executionInfo":{"status":"ok","timestamp":1637766438382,"user_tz":-540,"elapsed":419,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}},"outputId":"205ccbf2-ae95-42a6-818c-e67ff9ddd6f5"},"source":["!rm *_out.jpg"],"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove '*_out.jpg': No such file or directory\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kn2dpYpR-Q6V","executionInfo":{"status":"ok","timestamp":1637766441932,"user_tz":-540,"elapsed":596,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}},"outputId":"f00cbe54-97d8-49b3-8c2d-a177eb1bd414"},"source":["imagefile_infer('bird.jpg')"],"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Input image file  bird.jpg\n","bird_yolo_out.jpg\n","has frame !!!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c97VYDPfedav","executionInfo":{"status":"ok","timestamp":1637766446346,"user_tz":-540,"elapsed":258,"user":{"displayName":"KATE KIM","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi7n29K_FnNh1ndUAJAdAh-CHWNJjldcYPOVsRkYQQ=s64","userId":"08191676103652969482"}},"outputId":"6ca23b8d-1365-4af5-ce31-22fcc418b5db"},"source":["ls"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["accident2.mp4      how_to_download_weights.txt  run3.mp4\n","accident.mp4       LICENSE                      yolov3.cfg\n","bird.jpg           object_detection2.py         yolov3-tiny.cfg\n","bird_yolo_out.jpg  object_detection_yolo.cpp    yolov3-tiny.weights\n","CMakeLists.txt     object_detection_yolo.py     yolov3.weights\n","coco.names         people.mp4\n","getModels.sh       README.md\n"]}]},{"cell_type":"code","metadata":{"id":"WCWQhEkTfTfx"},"source":["imShow('bird_yolo_out.jpg')"],"execution_count":null,"outputs":[]}]}